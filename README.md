# 基于非参混合动态离散选择模型分析中国2010-2020年居民移动以及使用ABM模型进行反事实政策模拟

本项目使用 Python 实现了一个非参数混合的动态离散选择模型，用于分析中国的劳动力迁移决策。该模型受到 Kennan 和 Walker（2011）框架的启发，在其模型基础上引入了对户籍制度效应，并且使推力和拉力都在模型中得到了充分体现。

**请注意：项目中，build是使用LaTeX编译论文的单独项目，不与其他文件产生联动。**


## 项目结构


### 结构树

暂定如下

```bash
├── LICENSE
├── README.md
├── build
├── data
│   ├── geo
│   │   ├── adjacent.xlsx
│   │   ├── geo.xlsx
│   │   └── house_prix.xlsx
│   ├── interim
│   │   └── cfps10_22mc.dta
│   ├── processed
│   │   ├── adjacent.xlsx
│   │   ├── distance_matrix.csv
│   │   ├── geo.xlsx
│   │   ├── prov_code_ranked.json
│   │   └── prov_name_ranked.json
│   └── raw
│       ├── geo_backup
│       │   ├── adjacent
│       │   │   └── ADJ.xlsx
│       │   ├── 教育经费 万元.xls
│       │   ├── 交通事故.xls
│       │   ├── 初中师生比.xls
│       │   ├── 小学师生比.xls
│       │   ├── 普高师生比.xls
│       │   ├── 年末常住人口.xls
│       │   ├── 人均可支配收入.xls
│       │   ├── 人均日生活用水.xls
│       │   ├── 医疗卫生机构数.xls
│       │   ├── 医院平均住院日.xls
│       │   ├── 城市燃气普及率.xls
│       │   ├── 城市用水普及率.xls
│       │   ├── 地方财政医疗支出 亿元.xls
│       │   ├── 地方财政教育支出 亿元.xls
│       │   ├── 轨道交通运营里程 公里.xls
│       │   ├── 人均公园绿地面积.xls
│       │   ├── 连锁餐饮门店总数.xls
│       │   ├── 每万人卫生技术人员.xls
│       │   ├── 社会零售消费品总额.xls
│       │   ├── 公共汽电车运营总长度 公里.xls
│       │   ├── 每万人拥有公共厕所数量.xls
│       │   ├── 自然灾害受灾万人次人口.xls
│       │   ├── 每万人拥有公共交通车数量 标台.xls
│       │   ├── 每万人医疗卫生机构床位数.xls
│       │   ├── 每万人拥有公共交通车数量.xls
│       │   └── 城镇基本医疗保险年末参保人数.xls
│       ├── linguistic.json
│       ├── linguistic2.json
│       └── prov_language.csv
├── main.py
├── notes.md
├── pyproject.toml
├── results
│   ├── estimation
│   ├── figures
│   ├── logs
│   ├── policy
│   ├── tables
│   │   ├── move_add.tex
│   │   ├── move_add_proportion.tex
│   │   └── moved.tex
│   └── validation
├── scripts
│   ├── 00_prepare_data.py
│   ├── 01_train_ml_plugins.py
│   ├── 02_run_estimation.py
│   └── 03_run_abm_simulation.py
├── src
│   ├── abm
│   │   ├── __init__.py
│   │   ├── agents.py
│   │   ├── calibration.py
│   │   └── environment.py
│   ├── config
│   │   ├── __init__.py
│   │   ├── __pycache__
│   │   │   ├── __init__.cpython-311.pyc
│   │   │   └── model_config.cpython-311.pyc
│   │   └── model_config.py
│   ├── data_handler
│   │   ├── __init__.py
│   │   ├── __pycache__
│   │   │   ├── __init__.cpython-311.pyc
│   │   │   └── data_loader.cpython-311.pyc
│   │   ├── adjacent.py
│   │   ├── data_loader.py
│   │   ├── data_person.py
│   │   ├── data_region.py
│   │   ├── distance.py
│   │   ├── houseprice.py
│   │   ├── linguistic.py
│   │   └── subsample.py
│   ├── estimation
│   │   ├── __init__.py
│   │   ├── em_nfxp.py
│   │   ├── heterogeneity.py
│   │   └── inference.py
│   ├── ml_plugins
│   │   ├── __init__.py
│   │   ├── kfold_cv.py
│   │   └── wage_prediction.py
│   ├── model
│   │   ├── __init__.py
│   │   ├── bellman.py # 贝尔曼方程求解
│   │   ├── dynamic_model.py
│   │   ├── likelihood.py # 似然函数计算
│   │   ├── parameters.py # 参数管理
│   │   └── utility.py # 效用函数组件
│   ├── utils
│   │   ├── __init__.py
│   │   ├── computation.py
│   │   ├── entropy.py
│   │   ├── get_prov_code_rank.py
│   │   ├── indicator.py
│   │   ├── method_entropy.py
│   │   ├── method_pca.py
│   │   ├── outreg2.py
│   │   ├── parellel.py
│   │   ├── pca.py
│   │   ├── topsis.py
│   │   ├── validation.py
│   │   └── visited.py
│   └── visualization
│       ├── __init__.py
│       ├── policy_analysis.py
│       └── results_plot.py
├── test
│   ├── t_lightgbm.py
│   ├── t_mesa.py
│   └── ztest.py
└── uv.lock
```

### 数据构成与形式

- `file/geo.xlsx` 是地区相关数据，格式为面板数据，示例如下：

| provcd | year | health | education | ... |
|--------|------|--------|-----------|-----|
| 11     | 2010 | 4.1    | 4.2       | ... |
| 11     | 2011 | 6.1    | 6.2       | ... |
| 21     | 2010 | 4.5    | 4.7       | ... |
| 21     | 2011 | 5.4    | 4.9       | ... |
| ...    | ...  | ...    | ...       | ... |

其中：
- `provcd`：省份代码
- `year`：年份
- `health`：卫生指数
- `education`：教育指数

- `file/cfps10_20.dta` 是个体数据，格式为面板数据，示例如下：

| pid | year | provcd | age | wage | ... |
|-----|------|--------|-----|------|-----|
| 1   | 2010 | 11     | 20  | 1000 | ... |
| 1   | 2011 | 11     | 21  | 1200 | ... |
| 2   | 2010 | 11     | 20  | 2100 | ... |
| 2   | 2011 | 11     | 21  | 2600 | ... |
| ... | ...  | ...    | ... | ...  | ... |

其中：
- `pid`：个体标识符
- `year`：年份
- `provcd`：省份代码
- `age`：年龄
- `wage`：工资

此外，`file` 目录还包括一些矩阵文件，例如 `file/adjacent.xlsx` 为邻接矩阵；还有一些 JSON 文件，如 `file/linguistic.json` 为语言谱系树文件。


## 实现的结果与方法

### 程序成果清单：从微观参数到宏观洞见

#### 模块一：DDCM 核心估计模块 (对应 `\chapter{估计结果}`)

这是所有分析的基础，目标是得到一组稳健的、可解释的微观行为参数。

**1. 核心结构参数表 (`\ref{tab:结构参数的估计结果}`):**
-   **内容**:
    -   **效用函数参数**: `\alpha_w` (收入边际效用), `\alpha_s` (各项舒适度amenities的系数), `\alpha_{home}` (家乡溢价), `\lambda` (损失厌恶系数, 如果加入)。
    -   **户籍惩罚函数参数**: `\theta_{base}`, `\theta_{edu}`, `\theta_{health}`, `\theta_{house}`。
    -   **迁移成本函数参数**: `\gamma_1` (距离), `\gamma_2` (邻接), `\gamma_3` (历史), `\gamma_4` (年龄), `\gamma_5` (规模)。
    -   **工资函数参数**: `r_1`, `r_2` (年龄效应)，以及其他控制变量的系数。
    -   **折现因子**: `\beta` (如果是估计的)。
-   **格式**: 参数名 | 估计值 (Estimate) | 标准误 (Std. Error) | 显著性标记 (*, **, ***)。

**2. 有限混合模型结果表 (`\ref{tab:有限混合参数的 ઉ估计结果}`):**
-   **内容**:
    -   **类型占比**: `\pi_1`, `\pi_2`, `\pi_3` ...
    -   **类型特定的迁移成本**: `\gamma_{0, \tau=1}`, `\gamma_{0, \tau=2}`, `\gamma_{0, \tau=3}` ...
-   **格式**: 类型 (Type) | 占比 (Share, `\pi_\tau`) | 固定迁移成本 (Fixed Cost, `\gamma_{0\tau}`) | (对应的标准误)。
-   **作用**: 揭示人口中存在哪些不同的“行为模式”群体，并量化其规模。例如，您可能会发现一个占比60%的“高成本定居型”和一个占比10%的“低成本闯荡型”。

**3. 未观测异质性分布图/表:**
-   **内容**:
    *   对于 `\eta_i`, `\nu_{ij}`, `\xi_{ij}`, `\sigma_{\varepsilon,i}`，报告您估计出的**支撑点位置**。
-   **格式**:
    -   **表格**: 异质性来源 | 支撑点1 | 支撑点2 | ...
    -   **图形 (更佳)**: 画出这些支撑点的**直方图或核密度图**，直观展示这些未观测属性的分布形状（是否偏态、双峰等）。
-   **作用**: 展示您的非参数方法捕捉到的复杂分布形态，证明了放弃简单正态假设的必要性。

**4. 模型拟合检验结果:**
-   **内容**:
    -   **汇总指标**: 对数似然值, AIC/BIC, Brier Score。
    -   **关键矩的拟合图/表**:
        -   **图1 (生命周期迁移率)**: X轴为年龄，Y轴为迁移概率。一条线是真实数据，另一条线是模型模拟结果。
        -   **图2 (迁移流向矩阵/弦图)**: 展示模型模拟的主要省际人口流动与真实数据的对比。
        -   **表 (返乡率/省内迁移占比)**: 比较模型模拟值与真实数据值。
    -   **样本外预测精度表**: 报告用前期数据估计的模型在后期数据上的预测准确率 (Hit Rate) 或其他指标。
-   **作用**: 用证据告诉审稿人：“我的模型不仅理论复杂，而且能很好地拟合真实世界的数据。”

**5. 机制分解结果图 (`\sec:机制分解}`):**
-   **内容**:
    *   通常是一个**条形图 (Bar Chart)**。
    -   **Y轴**: 某个宏观结果，例如“全国平均迁移率”或“地区间人均收入差距”。
    -   **X轴**: 不同的反事实情景。
        *   Bar 1: 基准模型 (Baseline Model)。
        *   Bar 2: 无户籍惩罚 (No Hukou Penalty)。
        *   Bar 3: 无家乡溢价 (No Home Premium)。
        *   Bar 4: 无地理成本 (No Distance Cost)。
-   **作用**: 这是您DDCM部分故事性的高潮，直观地量化了不同摩擦对宏观格局的贡献。


#### 模块二：ABM 宏观模拟模块 (对应 `\chapter{与宏观桥接}`)

这是将您的研究从小世界推向大世界的关键，目标是展示模型的宏观解释力和政策模拟能力。

**6. ABM模型校准结果表:**
-   **内容**:
    -   **目标矩**: 您选择用于校准的10-30个宏观矩（如省际净流入率、返乡率等）。
    -   **真实值 vs 模拟值**: 清晰地列出每个矩的真实数据值，以及您校准好的ABM模型模拟出的均值和95%置信区间。
-   **格式**: 目标矩 (Target Moment) | 真实数据 (Data) | 模型模拟均值 (Model Mean) | 模型模拟95% CI。
-   **作用**: 证明您的ABM平台是经过“宏观事实”锚定的，其模拟结果具有外部有效性。

**7. 宏观涌现模式验证图 (`\sub:abm模型的检验}`):**
-   **内容**:
    -   **图1 (城市规模分布)**: Log-log图，X轴为城市排名的对数，Y轴为城市人口的对数。一条线是真实数据，另一条是ABM模拟结果，看是否都近似一条直线（齐普夫定律）。
    -   **图2 (人口空间分布图)**: 两张中国地图，一张用真实数据染色显示各省人口密度，另一张用ABM模拟的长期均衡结果染色。看是否能再现“胡焕庸线”等宏观格局。
-   **作用**: 展示您的模型不仅能拟合您用来校准的矩，还能“涌现”出一些您并未直接校准的、更高层次的宏观规律。这是模型强大的标志。

**8. 核心政策实验结果图/表 (`\section{反事实参数估计}`):**
-   **这是您ABM部分故事性的高潮，也是政策建议的核心依据。**
-   **内容**:
    *   对于每个政策实验（如“二线城市吸引力提升”），输出一系列**动态演化图 (Time-path Plots)**。
    -   **图1 (主要城市人口路径)**: X轴为年份（从2022到2042），Y轴为人口。图中包含几条线：北京（基准 vs 政策）、上海（基准 vs 政策）、成都（基准 vs 政策）、武汉（基准 vs 政策）。
    -   **图2 (全国不平等指数路径)**: X轴为年份，Y轴为基尼/泰尔指数。一条线是基准情景，另一条是政策情景。
    -   **图3 (社会福利路径)**: X轴为年份，Y轴为加总的个体效用或等价收入。
-   **作用**: 将政策影响从一个静态的数字变成一个动态的故事，展示短期、中期、长期的不同效果以及可能的非预期后果。

**9. 稳健性与权衡分析图:**
-   **内容**:
    -   **图 (Pareto前沿)**: 如您所设想的，X轴为“地区均衡”（如人口集中度下降），Y轴为“总福利/产出”。图中的每个点代表一种政策强度或组合，连接起来形成效率与公平的权衡曲线。
    -   **表/图 (敏感性分析)**: 展示当外部性参数 `η_1, η_2` 等变化时，政策实验的核心结论是否依然成立。
-   **作用**: 展示您对模型和政策复杂性的深刻理解，表明您的政策建议不是“一招鲜”，而是存在复杂的权衡取舍。




### 项目实现方案

本项目将按照以下阶段进行实施：

1.  **数据准备 (`scripts/00_prepare_data.py`):**
    *   **目标**: 加载原始数据，进行清洗、预处理，并构建模型所需的特征和矩阵。
    *   **具体任务**:
        *   从 `data/raw` 和 `data/interim` 加载个体 (`cfps10_22mc.dta`) 和地区 (`geo.xlsx`) 面板数据。
        *   清洗数据，处理缺失值，统一数据格式。
        *   根据 `data/geo/adjacent.xlsx` 构建地区邻接矩阵。
        *   计算地区间的距离矩阵（可利用 `src/data_handler/distance.py`）。
        *   从 `data/raw/linguistic.json` 处理语言谱系数据，生成语言距离或相似性特征。
        *   根据模型需求，从原始地区数据 (`data/raw/geo_backup`) 提取并构建各项舒适度 (amenities) 指数、户籍惩罚相关指标（教育、医疗、住房等）。
        *   将处理后的数据保存至 `data/processed` 目录，供后续模型使用。

2.  **ML 插件训练 (`scripts/01_train_ml_plugins.py`):**
    *   **目标**: 训练机器学习模型以非参数化地估计滋扰函数，如工资方程。
    *   **具体任务**:
        *   实现 `src/ml_plugins/wage_prediction.py`，使用 LightGBM 预测个体工资。
        *   应用 `src/ml_plugins/kfold_cv.py` 实现 K 折交叉拟合策略，以防止过拟合和信息泄露。
        *   训练其他可能需要的滋扰函数（例如，如果模型中包含内生状态转移，则需估计其转移概率）。
        *   保存训练好的模型或其预测结果，供 DDCM 估计模块使用。

3.  **DDCM 核心估计 (`scripts/02_run_estimation.py`):**
    *   **目标**: 基于 EM-NFXP 框架估计动态离散选择模型的结构参数。
    *   **具体任务**:
        *   **配置管理 (`src/config/model_config.py`)**: 定义所有超参数，包括未观测异质性的支撑点数量、EM 迭代次数、NFXP 收敛标准、学习率等。
        *   **参数定义 (`src/model/parameters.py`)**: 使用 `dataclasses` 和 `torch.nn.Module` 封装所有待估结构参数 (`alpha_w`, `lambda`, `alpha_s`, `alpha_home`, `theta_*`, `gamma_*`, `beta` 等)，并定义为 `torch.nn.Parameter`。
        *   **效用函数 (`src/model/utility.py`)**: 实现 `notes.md` 中定义的总效用函数，包括收入效用（前景理论）、各项舒适度、家乡溢价、户籍惩罚和迁移成本。
        *   **贝尔曼方程求解 (`src/model/bellman.py`)**: 实现反向归纳法 (Backward Induction) 算法，迭代求解贝尔曼方程，得到各状态下的期望价值函数。
        *   **动态模型整合 (`src/model/dynamic_model.py`)**: 整合效用函数和贝尔曼方程，计算选择概率。
        *   **似然函数 (`src/model/likelihood.py`)**: 实现 EM 算法所需的个体对数似然函数。
        *   **EM-NFXP 算法 (`src/estimation/em_nfxp.py`)**: 
            *   **E 步**: 计算每个个体属于不同未观测异质性类型/支撑点的后验概率。
            *   **M 步**: 使用 `torch.optim.LBFGS` 优化器，在给定后验概率下最大化期望对数似然，更新结构参数。M 步中需嵌套 NFXP 求解贝尔曼方程。
        *   **异质性处理 (`src/estimation/heterogeneity.py`)**: 管理有限混合模型和离散支撑点近似。
        *   **推断 (`src/estimation/inference.py`)**: 计算 BHHH 估计量以获得参数标准误，并进行沃尔德检验。
        *   **模型选择**: 运行不同支撑点数量的模型估计，并根据 BIC 准则选择最优模型。
        *   将估计结果（参数估计值、标准误、显著性、BIC 值等）保存至 `results/estimation`。

4.  **ABM 宏观模拟 (`scripts/03_run_abm_simulation.py`):**
    *   **目标**: 利用估计出的微观参数进行宏观模拟，验证涌现模式，并进行反事实政策分析。
    *   **具体任务**:
        *   **智能体定义 (`src/abm/agents.py`)**: 根据 DDCM 估计结果，定义具有异质性的智能体，其决策行为遵循估计出的选择概率。
        *   **环境定义 (`src/abm/environment.py`)**: 构建模拟环境，包括地区特征、人口分布、宏观状态变量及其动态演化规则。
        *   **校准 (`src/abm/calibration.py`)**: 如果需要，校准 ABM 特有的宏观参数，使其模拟出的宏观矩与真实数据匹配 (SMM)。
        *   **模拟逻辑**: 运行 ABM 模拟，追踪个体迁移决策和宏观变量的动态演化。
        *   **政策分析 (`src/visualization/policy_analysis.py`)**: 设计并执行反事实政策实验，例如改变户籍政策、地区吸引力等。
        *   **结果可视化 (`src/visualization/results_plot.py`)**: 
            *   绘制宏观涌现模式图（如城市规模分布、人口空间分布）。
            *   绘制政策实验结果的动态演化图（如主要城市人口路径、全国不平等指数、社会福利路径）。
            *   进行稳健性与权衡分析（如 Pareto 前沿图、敏感性分析）。
        *   将模拟输出、图表保存至 `results/policy` 和 `results/figures`。

5.  **通用工具 (`src/utils/`):**
    *   `computation.py`: 提供通用的数学计算和数值处理函数。
    *   `parellel.py`: 封装 `joblib` 库，用于并行计算个体似然函数等计算密集型任务。
    *   `outreg2.py`: 用于生成格式化的估计结果输出（例如 LaTeX 表格）。
    *   其他现有工具（如 `pca.py`, `topsis.py`, `entropy.py`）可根据数据处理和指标构建需求进行整合和完善。


### 项目技术栈核心摘要

-   **环境管理**: **UV**。通过 `pyproject.toml` 文件进行声明式依赖管理，确保开发与部署环境的统一与可复现性。
-   **项目结构**: **分层模块化**。采用 `src`, `scripts`, `data`, `results` 的清晰目录结构，将模型逻辑、执行流程、原始数据与输出结果完全分离。
-   **配置管理**: **集中式配置**。使用独立的Python模块 (`src/config/model_config.py`) 定义所有超参数（支撑点数量、路径、学习率等），避免硬编码，便于进行实验和调试。
-   **参数管理**: **PyTorch参数模块**。使用dataclasses来进行一个优雅的Pythonic方式，将所有待估结构参数封装于一个继承自 `torch.nn.Module` 的类中，每个参数定义为 `torch.nn.Parameter`，从而能够利用PyTorch的自动微分引擎计算梯度。
-   **模型选择**: **信息准则驱动**。通过系统性地改变未观测异-质性离散支撑点的数量，对多个模型设定进行估计，并最终依据贝叶斯信息准-则 (BIC) 来选择最优的模型复杂度。整个过程由配置驱动的自动化脚本执行，以在模型拟合优度与简约性之间取得最佳平衡。
-   **算法框架**: **EM + NFXP**。外层使用**期望最大化 (EM)** 算法处理未观测异质性；内层（M步）使用**嵌套不动点 (NFXP)** 算法求解动态规划问题，整个优化过程由PyTorch驱动。
-   **核心求解器**: **价值函数迭代**。通过**反向归纳法** (Backward Induction)，从生命周期最后一期开始，逆向迭代求解贝尔曼方程，得到各状态下的期望价值函数。
-   **异质性**
-   **优化器**: **L-BFGS**。在M步中，采用 `torch.optim.LBFGS` 这一拟牛顿法优化器。它仅需梯度信息即可高效逼近海森矩阵，兼顾了收敛速度与计算效率。
-   **ML插件**: **LightGBM + 交叉拟合**。使用预训练的 **LightGBM** 模型来非参数化地估计滋扰函数（如工资方程）。采用**K折交叉拟合** (K-fold Cross-fitting) 策略，防止信息泄露和过拟合。
-   **向量化计算**: **NumPy / PyTorch张量运算**。在效用函数、选择概率和似然函数等计算密集型环节，用张量运算全面替代Python原生循环，以获得数量级的性能提升。
-   **并行计算**: **Joblib并行化**。利用 `joblib` 库将计算成本最高的**个体似然函数**的计算任务，并行地分配到所有可用的CPU核心上执行，显著缩短估计总耗时。
-   **标准误计算**: **BHHH估计量**。模型收敛后，通过计算每个个体对数似然梯度的**外积之和** (Outer Product of Gradients) 来构造BHHH海森矩阵估计量，其逆矩阵的对角线元素即为参数方差的估计。
-   **假设检验**: **沃尔德检验 (Wald Test)**。基于估计出的参数值及其标准误，构造z统计量，进行标准的沃尔德检验，以判断各参数的统计显著性。
-   **拟合优度评估**:
    -   **结构模型**: 对比模型预测的**选择概率/关键矩**（如分年龄迁移率、返乡率）与样本观测值，使用交叉熵 (Cross-Entropy)、布莱尔分数 (Brier Score) 等指标进行评估。
    -   **ABM**: 采用**模拟矩匹配 (SMM)**。检验ABM涌现出的宏观模式（如城市规模分布、区域人口差距）是否能拟合真实世界的宏观矩。
